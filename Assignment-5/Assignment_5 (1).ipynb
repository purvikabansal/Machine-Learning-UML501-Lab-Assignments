{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_kXi7ObKJaW",
        "outputId": "e258dfd9-8049-4a64-d100-5224acd141aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.0001 lambda: 1e-15 cost: 1.0460451927680494 R2: 0.9394108801075687\n",
            "lr: 0.0001 lambda: 1e-10 cost: 1.0460451927688204 R2: 0.9394108801075569\n",
            "lr: 0.0001 lambda: 1e-05 cost: 1.0460452702055563 R2: 0.9394108789062035\n",
            "lr: 0.0001 lambda: 0.001 cost: 1.0460529365159037 R2: 0.9394107599709982\n",
            "lr: 0.0001 lambda: 0 cost: 1.0460451927680494 R2: 0.9394108801075687\n",
            "lr: 0.0001 lambda: 1 cost: 1.053785764408221 R2: 0.9392907116627753\n",
            "lr: 0.0001 lambda: 10 cost: 1.123165749575376 R2: 0.9382063456685797\n",
            "lr: 0.0001 lambda: 20 cost: 1.1996567570939654 R2: 0.9369955683555288\n",
            "lr: 0.001 lambda: 1e-15 cost: 0.006133709440266483 R2: 0.9995681821801614\n",
            "lr: 0.001 lambda: 1e-10 cost: 0.006133709441273493 R2: 0.9995681821801617\n",
            "lr: 0.001 lambda: 1e-05 cost: 0.006133810142349584 R2: 0.9995681822136135\n",
            "lr: 0.001 lambda: 0.001 cost: 0.006143779642642159 R2: 0.9995681855250091\n",
            "lr: 0.001 lambda: 0 cost: 0.006133709440266473 R2: 0.9995681821801614\n",
            "lr: 0.001 lambda: 1 cost: 0.016197926526472887 R2: 0.9995711591617713\n",
            "lr: 0.001 lambda: 10 cost: 0.10623985575355549 R2: 0.9995652009868895\n",
            "lr: 0.001 lambda: 20 cost: 0.20516815114055667 R2: 0.9994910579795552\n",
            "lr: 0.01 lambda: 1e-15 cost: 0.005794986405758411 R2: 0.9996055982097474\n",
            "lr: 0.01 lambda: 1e-10 cost: 0.005794986406765456 R2: 0.9996055982097476\n",
            "lr: 0.01 lambda: 1e-05 cost: 0.005795087111654108 R2: 0.999605598231325\n",
            "lr: 0.01 lambda: 0.001 cost: 0.005805056989373019 R2: 0.9996056003671517\n",
            "lr: 0.01 lambda: 0 cost: 0.005794986405758399 R2: 0.9996055982097474\n",
            "lr: 0.01 lambda: 1 cost: 0.01585956425709001 R2: 0.9996073884310716\n",
            "lr: 0.01 lambda: 10 cost: 0.10590346928732627 R2: 0.9995908109508244\n",
            "lr: 0.01 lambda: 20 cost: 0.2048326449777229 R2: 0.9995049981411169\n",
            "lr: 0.1 lambda: 1e-15 cost: 0.005754200857066153 R2: 0.999605629986567\n",
            "lr: 0.1 lambda: 1e-10 cost: 0.005754200858076914 R2: 0.9996056299865672\n",
            "lr: 0.1 lambda: 1e-05 cost: 0.005754301934848452 R2: 0.9996056300081607\n",
            "lr: 0.1 lambda: 0.001 cost: 0.005764308608787809 R2: 0.9996056321455722\n",
            "lr: 0.1 lambda: 0 cost: 0.005754200857066143 R2: 0.999605629986567\n",
            "lr: 0.1 lambda: 1 cost: 0.01584160215210049 R2: 0.9996074178727598\n",
            "lr: 0.1 lambda: 10 cost: 0.10590294762405346 R2: 0.9995908170629416\n",
            "lr: 0.1 lambda: 20 cost: 0.2048325957035607 R2: 0.9995050000806915\n",
            "lr: 1 lambda: 1e-15 cost: 14433591866143.496 R2: -882868432048.2849\n",
            "lr: 1 lambda: 1e-10 cost: 14433591866140.627 R2: -882868432048.0566\n",
            "lr: 1 lambda: 1e-05 cost: 14433591579160.625 R2: -882868409238.4908\n",
            "lr: 1 lambda: 0.001 cost: 14433563167793.18 R2: -882866151066.3845\n",
            "lr: 1 lambda: 0 cost: 14433591866143.496 R2: -882868432048.2849\n",
            "lr: 1 lambda: 1 cost: 14404829123693.28 R2: -880584869488.4255\n",
            "lr: 1 lambda: 10 cost: 14140162527952.648 R2: -859801640411.7222\n",
            "lr: 1 lambda: 20 cost: 13833847637251.174 R2: -836227347201.0629\n",
            "lr: 10 lambda: 1e-15 cost: 2351767443943609.5 R2: -137525702678850.61\n",
            "lr: 10 lambda: 1e-10 cost: 2351767443943703.5 R2: -137525702678850.08\n",
            "lr: 10 lambda: 1e-05 cost: 2351767456159796.0 R2: -137525702584616.73\n",
            "lr: 10 lambda: 0.001 cost: 2351768665559047.0 R2: -137525693255509.14\n",
            "lr: 10 lambda: 0 cost: 2351767443943609.5 R2: -137525702678850.61\n",
            "lr: 10 lambda: 1 cost: 2352988919858898.0 R2: -137516276639483.84\n",
            "lr: 10 lambda: 10 cost: 2363969613437988.5 R2: -137431199279909.94\n",
            "lr: 10 lambda: 20 cost: 2376143709542414.0 R2: -137336156252845.4\n",
            "Best learning rate: 0.1\n",
            "Best lambda: 0\n",
            "Minimum cost: 0.005754200857066143\n",
            "Max R2 on test: 0.999605629986567\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "z = np.random.randn(n_samples, 1)\n",
        "x1 = z + 0.01 * np.random.randn(n_samples, 1)\n",
        "x2 = z * 1.1 + 0.01 * np.random.randn(n_samples, 1)\n",
        "x3 = z * 0.9 + 0.01 * np.random.randn(n_samples, 1)\n",
        "x4 = 2 * z + 0.01 * np.random.randn(n_samples, 1)\n",
        "x5 = -1.5 * z + 0.01 * np.random.randn(n_samples, 1)\n",
        "x6 = 0.5 * z + 0.01 * np.random.randn(n_samples, 1)\n",
        "x7 = -0.7 * z + 0.01 * np.random.randn(n_samples, 1)\n",
        "X = np.hstack([x1, x2, x3, x4, x5, x6, x7])\n",
        "true_w = np.array([[3], [-2], [1.5], [0.7], [-1], [2], [0.5]])\n",
        "y = (X @ true_w).ravel() + 0.1 * np.random.randn(n_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def ridge_gradient_descent(X, y, lr, lambd, n_iters=2000):\n",
        "    n_samples, n_features = X.shape\n",
        "    w = np.zeros(n_features)\n",
        "    b = 0.0\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ w + b\n",
        "        error = y_pred - y\n",
        "        dw = (X.T @ error) / n_samples + (lambd / n_samples) * w\n",
        "        db = np.sum(error) / n_samples\n",
        "        dw = np.clip(dw, -1e6, 1e6)\n",
        "        db = float(np.clip(db, -1e6, 1e6))\n",
        "        w -= lr * dw\n",
        "        b -= lr * db\n",
        "        if not np.all(np.isfinite(w)) or not np.isfinite(b):\n",
        "            return None, None\n",
        "    return w, b\n",
        "\n",
        "def ridge_cost(X, y, w, b, lambd):\n",
        "    n_samples = X.shape[0]\n",
        "    y_pred = X @ w + b\n",
        "    mse = np.mean((y_pred - y) ** 2)\n",
        "    reg = lambd * np.sum(w ** 2) / (2 * n_samples)\n",
        "    return 0.5 * mse + reg\n",
        "\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
        "lambdas = [1e-15, 1e-10, 1e-5, 1e-3, 0, 1, 10, 20]\n",
        "\n",
        "best_params = None\n",
        "best_cost = float(\"inf\")\n",
        "best_r2 = -float(\"inf\")\n",
        "best_model = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for lambd in lambdas:\n",
        "        w, b = ridge_gradient_descent(X_train_scaled, y_train, lr, lambd, n_iters=2000)\n",
        "        if w is None:\n",
        "            continue\n",
        "        cost = ridge_cost(X_train_scaled, y_train, w, b, lambd)\n",
        "        if not np.isfinite(cost):\n",
        "            continue\n",
        "        y_pred_test = X_test_scaled @ w + b\n",
        "        if not np.all(np.isfinite(y_pred_test)):\n",
        "            continue\n",
        "        r2 = r2_score(y_test, y_pred_test)\n",
        "        print(\"lr:\", lr, \"lambda:\", lambd, \"cost:\", cost, \"R2:\", r2)\n",
        "        if (cost < best_cost) or (np.isclose(cost, best_cost) and r2 > best_r2):\n",
        "            best_cost = cost\n",
        "            best_r2 = r2\n",
        "            best_params = (lr, lambd)\n",
        "            best_model = (w, b)\n",
        "\n",
        "print(\"Best learning rate:\", best_params[0])\n",
        "print(\"Best lambda:\", best_params[1])\n",
        "print(\"Minimum cost:\", best_cost)\n",
        "print(\"Max R2 on test:\", best_r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2\n"
      ],
      "metadata": {
        "id": "-YL0Ew0NMcXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "df = pd.read_csv(\"/content/Hitters (1).csv\")\n",
        "df = df.dropna()\n",
        "\n",
        "y = df[\"Salary\"].values\n",
        "X = df.drop(columns=[\"Salary\"])\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(alpha=1.0),\n",
        "    \"Lasso\": Lasso(alpha=0.1, max_iter=10000)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    results[name] = (r2, mse)\n",
        "\n",
        "for name in results:\n",
        "    print(name, \"R2:\", results[name][0], \"MSE:\", results[name][1])\n",
        "\n",
        "best_model = max(results.items(), key=lambda x: x[1][0])\n",
        "print(\"Best model by R2:\", best_model[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-SDdeciMdVi",
        "outputId": "5b859812-6eb8-4b6b-c066-ed9a36b83d5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression R2: 0.29074518557981455 MSE: 128284.34549672344\n",
            "Ridge R2: 0.2994019064058938 MSE: 126718.5869812465\n",
            "Lasso R2: 0.29279784955454047 MSE: 127913.07603309958\n",
            "Best model by R2: Ridge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3\n"
      ],
      "metadata": {
        "id": "ktA1egQsQbo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "df = pd.read_csv(\"/content/Hitters (1).csv\")\n",
        "df = df.dropna()\n",
        "\n",
        "y = df[\"Salary\"].values\n",
        "X = df.drop(columns=[\"Salary\"])\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "ridge_reg = Ridge(alpha=0.5748)\n",
        "lasso_reg = Lasso(alpha=0.5748, max_iter=10000)\n",
        "\n",
        "lin_reg.fit(X_train_scaled, y_train)\n",
        "ridge_reg.fit(X_train_scaled, y_train)\n",
        "lasso_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "for name, model in [(\"Linear\", lin_reg), (\"Ridge\", ridge_reg), (\"Lasso\", lasso_reg)]:\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(name, \"R2:\", r2, \"MSE:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0l0-hzGQcoz",
        "outputId": "49dd586c-12a7-4f54-c8ef-a62f6cf1d266"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear R2: 0.29074518557981455 MSE: 128284.34549672344\n",
            "Ridge R2: 0.3000359698829351 MSE: 126603.9026442468\n",
            "Lasso R2: 0.2996256609856722 MSE: 126678.11604014723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=r\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "X_boston = data\n",
        "y_boston = target\n",
        "\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
        "    X_boston, y_boston, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_b = StandardScaler()\n",
        "X_train_b_scaled = scaler_b.fit_transform(X_train_b)\n",
        "X_test_b_scaled = scaler_b.transform(X_test_b)\n",
        "\n",
        "alphas = [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10]\n",
        "\n",
        "ridge_cv = RidgeCV(alphas=alphas, scoring=\"r2\", cv=5)\n",
        "ridge_cv.fit(X_train_b_scaled, y_train_b)\n",
        "y_pred_ridge_cv = ridge_cv.predict(X_test_b_scaled)\n",
        "r2_ridge_cv = r2_score(y_test_b, y_pred_ridge_cv)\n",
        "\n",
        "lasso_cv = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
        "lasso_cv.fit(X_train_b_scaled, y_train_b)\n",
        "y_pred_lasso_cv = lasso_cv.predict(X_test_b_scaled)\n",
        "r2_lasso_cv = r2_score(y_test_b, y_pred_lasso_cv)\n",
        "\n",
        "print(\"RidgeCV best alpha:\", ridge_cv.alpha_)\n",
        "print(\"RidgeCV test R2:\", r2_ridge_cv)\n",
        "print(\"LassoCV best alpha:\", lasso_cv.alpha_)\n",
        "print(\"LassoCV test R2:\", r2_lasso_cv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcJgO_CpQrfo",
        "outputId": "ff63e281-e31e-4822-c543-5a2ccbbb4de6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RidgeCV best alpha: 1.0\n",
            "RidgeCV test R2: 0.668462435964356\n",
            "LassoCV best alpha: 0.0001\n",
            "LassoCV test R2: 0.6687548978932025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4\n"
      ],
      "metadata": {
        "id": "Ulm1INn_Q9n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def train_binary_logistic(X, y, lr=0.1, n_iters=3000, lambd=0.0):\n",
        "    n_samples, n_features = X.shape\n",
        "    w = np.zeros(n_features)\n",
        "    b = 0.0\n",
        "    for _ in range(n_iters):\n",
        "        linear = X @ w + b\n",
        "        y_pred = sigmoid(linear)\n",
        "        error = y_pred - y\n",
        "        dw = (X.T @ error) / n_samples + (lambd / n_samples) * w\n",
        "        db = np.sum(error) / n_samples\n",
        "        w -= lr * dw\n",
        "        b -= lr * db\n",
        "    return w, b\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "n_classes = len(classes)\n",
        "n_features = X_train_scaled.shape[1]\n",
        "\n",
        "W = np.zeros((n_classes, n_features))\n",
        "b_vec = np.zeros(n_classes)\n",
        "\n",
        "for idx, c in enumerate(classes):\n",
        "    y_binary = (y_train == c).astype(int)\n",
        "    w_c, b_c = train_binary_logistic(X_train_scaled, y_binary, lr=0.1, n_iters=5000, lambd=0.01)\n",
        "    W[idx] = w_c\n",
        "    b_vec[idx] = b_c\n",
        "\n",
        "def predict_ovr(X, W, b_vec):\n",
        "    logits = X @ W.T + b_vec\n",
        "    probs = sigmoid(logits)\n",
        "    return np.argmax(probs, axis=1)\n",
        "\n",
        "y_pred_test = predict_ovr(X_test_scaled, W, b_vec)\n",
        "acc = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Test accuracy (OvR logistic):\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtjorKgtQ-ov",
        "outputId": "f8c452dd-9d93-4752-97a2-d111a784d64e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy (OvR logistic): 0.9\n"
          ]
        }
      ]
    }
  ]
}