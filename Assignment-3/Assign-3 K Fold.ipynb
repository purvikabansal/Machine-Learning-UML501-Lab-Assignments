{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03095a87-8e71-44c1-a661-d8077755bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51b1865-3989-4d84-b862-78888d0e7869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold R2: [0.9179971706985147, 0.9145677884802819, 0.9116116385364478, 0.9193091764960816, 0.9243869413350316]\n",
      "Best Fold: 5 R2: 0.9243869413350316\n",
      "Final 70/30 R2: 0.9149217287708293\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\NEW\\\\Downloads\\\\USA_Housing (1).csv\")\n",
    "X = df.drop(columns=[\"Price\"]).values\n",
    "y = df[\"Price\"].values.reshape(-1,1)\n",
    "\n",
    "def add_bias(X):\n",
    "    return np.hstack([np.ones((X.shape[0],1)), X])\n",
    "\n",
    "def normal_beta(X,y):\n",
    "    return np.linalg.inv(X.T@X)@X.T@y\n",
    "\n",
    "def r2(y,y_hat):\n",
    "    return 1 - np.sum((y-y_hat)**2)/np.sum((y-y.mean())**2)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "scores, betas = [], []\n",
    "\n",
    "for tr,te in kf.split(X):\n",
    "    scaler = StandardScaler().fit(X[tr])\n",
    "    Xtr,Xte = scaler.transform(X[tr]), scaler.transform(X[te])\n",
    "    Xtr,Xte = add_bias(Xtr), add_bias(Xte)\n",
    "    beta = normal_beta(Xtr,y[tr])\n",
    "    y_hat = Xte@beta\n",
    "    scores.append(r2(y[te],y_hat))\n",
    "    betas.append(beta)\n",
    "\n",
    "best = np.argmax(scores)\n",
    "print(\"Fold R2:\",scores)\n",
    "print(\"Best Fold:\",best+1,\"R2:\",scores[best])\n",
    "\n",
    "Xtr,Xte,ytr,yte = train_test_split(X,y,test_size=0.3,random_state=7)\n",
    "scaler = StandardScaler().fit(Xtr)\n",
    "Xtr,Xte = scaler.transform(Xtr),scaler.transform(Xte)\n",
    "Xtr,Xte = add_bias(Xtr),add_bias(Xte)\n",
    "beta = normal_beta(Xtr,ytr)\n",
    "print(\"Final 70/30 R2:\",r2(yte,Xte@beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfad89-2063-4a7a-89ae-59baffe16309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aabc4595-6a6d-4013-958b-e70a0d8314ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 Val R2: 0.6752036751540692 Test R2: 0.6861452071726952\n",
      "0.01 Val R2: 0.9219863357213828 Test R2: 0.9167072198129036\n",
      "0.1 Val R2: 0.9219864090633332 Test R2: 0.9167072348076073\n",
      "1 Val R2: -inf Test R2: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEW\\AppData\\Local\\Temp\\ipykernel_24680\\2515729893.py:17: RuntimeWarning: overflow encountered in square\n",
      "  return 1 - np.sum((y-y_hat)**2)/np.sum((y-y.mean())**2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtr_temp,Xtest,ytr_temp,ytest = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "Xtrain,Xval,ytrain,yval = train_test_split(Xtr_temp,ytr_temp,test_size=0.2,random_state=1)\n",
    "\n",
    "scaler = StandardScaler().fit(Xtrain)\n",
    "Xtrain,Xval,Xtest = scaler.transform(Xtrain),scaler.transform(Xval),scaler.transform(Xtest)\n",
    "Xtrain,Xval,Xtest = add_bias(Xtrain),add_bias(Xval),add_bias(Xtest)\n",
    "\n",
    "def gd(X,y,lr,iters):\n",
    "    beta = np.zeros((X.shape[1],1))\n",
    "    for _ in range(iters):\n",
    "        grad = -2/X.shape[0]*X.T@(y-X@beta)\n",
    "        beta -= lr*grad\n",
    "    return beta\n",
    "\n",
    "rates = [0.001,0.01,0.1,1]\n",
    "for lr in rates:\n",
    "    beta = gd(Xtrain,ytrain,lr,1000)\n",
    "    r2_val = r2(yval,Xval@beta)\n",
    "    r2_test = r2(ytest,Xtest@beta)\n",
    "    print(lr,\"Val R2:\",r2_val,\"Test R2:\",r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004af2a1-fe6f-4979-939e-0414b6d3b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a36eee9-2591-4305-a0e3-672a4b16f915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original R2: 0.8734104772978125\n",
      "PCA R2: 0.8310865902221483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEW\\AppData\\Local\\Temp\\ipykernel_24680\\606511686.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df2[c]=df2[c].map({\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"eight\":8,\"twelve\":12}).fillna(df2[c])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cols=[\"symboling\",\"normalized_losses\",\"make\",\"fuel_type\",\"aspiration\",\"num_doors\",\"body_style\",\"drive_wheels\",\"engine_location\",\"wheel_base\",\"length\",\"width\",\"height\",\"curb_weight\",\"engine_type\",\"num_cylinders\",\"engine_size\",\"fuel_system\",\"bore\",\"stroke\",\"compression_ratio\",\"horsepower\",\"peak_rpm\",\"city_mpg\",\"highway_mpg\",\"price\"]\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\NEW\\\\Downloads\\\\imports-85.data\",names=cols)\n",
    "df2.replace(\"?\",np.nan,inplace=True)\n",
    "df2[\"price\"]=pd.to_numeric(df2[\"price\"],errors=\"coerce\")\n",
    "df2.dropna(subset=[\"price\"],inplace=True)\n",
    "for c in df2.columns:\n",
    "    if df2[c].dtype==\"O\" and c!=\"price\":\n",
    "        if c in [\"num_doors\",\"num_cylinders\"]:\n",
    "            df2[c]=df2[c].map({\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"eight\":8,\"twelve\":12}).fillna(df2[c])\n",
    "        elif c in [\"body_style\",\"drive_wheels\"]:\n",
    "            dummies=pd.get_dummies(df2[c],prefix=c)\n",
    "            df2=pd.concat([df2.drop(c,axis=1),dummies],axis=1)\n",
    "        elif c in [\"make\",\"aspiration\",\"engine_location\",\"fuel_type\"]:\n",
    "            df2[c]=LabelEncoder().fit_transform(df2[c].astype(str))\n",
    "        elif c==\"fuel_system\":\n",
    "            df2[c]=df2[c].apply(lambda x:1 if \"pfi\" in str(x) else 0)\n",
    "        elif c==\"engine_type\":\n",
    "            df2[c]=df2[c].apply(lambda x:1 if \"ohc\" in str(x) else 0)\n",
    "df2=df2.apply(pd.to_numeric,errors=\"coerce\")\n",
    "df2.fillna(df2.median(),inplace=True)\n",
    "\n",
    "X=df2.drop(columns=[\"price\"]).values\n",
    "y=df2[\"price\"].values\n",
    "scaler=StandardScaler().fit(X)\n",
    "X=scaler.transform(X)\n",
    "Xtr,Xte,ytr,yte=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "lr=LinearRegression().fit(Xtr,ytr)\n",
    "print(\"Original R2:\",lr.score(Xte,yte))\n",
    "\n",
    "pca=PCA(n_components=10).fit(X)\n",
    "X_pca=pca.transform(X)\n",
    "Xtr,Xte,ytr,yte=train_test_split(X_pca,y,test_size=0.3,random_state=42)\n",
    "lr=LinearRegression().fit(Xtr,ytr)\n",
    "print(\"PCA R2:\",lr.score(Xte,yte))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf941f10-8bce-4588-96f7-6bb9d8d0f566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
